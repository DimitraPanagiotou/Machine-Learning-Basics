{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T11:47:21.821559Z",
     "start_time": "2021-11-27T11:47:21.784659Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sns\n",
    "from keras import regularizers\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy import concatenate\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "import collections\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from semisupervised import S3VM\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.semi_supervised import LabelPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T09:39:53.869696Z",
     "start_time": "2021-11-27T09:39:53.832788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>C4_enc</th>\n",
       "      <th>C5_enc</th>\n",
       "      <th>C6_enc</th>\n",
       "      <th>N7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>N10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12_enc</th>\n",
       "      <th>N13</th>\n",
       "      <th>N14</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.46</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.17</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C1     N2     N3  C4_enc  C5_enc  C6_enc     N7  C8  C9  N10  C11  C12_enc  \\\n",
       "0   1  22.08  11.46       2       4       4  1.585   0   0    0    1        2   \n",
       "1   0  22.67   7.00       2       8       4  0.165   0   0    0    0        2   \n",
       "2   0  29.58   1.75       1       4       4  1.250   0   0    0    1        2   \n",
       "3   0  21.67  11.50       1       5       3  0.000   1   1   11    1        2   \n",
       "4   1  20.17   8.17       2       6       4  1.960   1   1   14    0        2   \n",
       "\n",
       "   N13   N14  Target  \n",
       "0  100  1213       0  \n",
       "1  160     1       0  \n",
       "2  280     1       0  \n",
       "3    0     1       1  \n",
       "4   60   159       1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('credit_approval.csv')\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T09:39:57.974067Z",
     "start_time": "2021-11-27T09:39:57.956114Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['New Label'] = dataset['Target']\n",
    "#create unlabeled data\n",
    "dataset.loc[100:, 'New Label'] = -1\n",
    "\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T09:40:01.188791Z",
     "start_time": "2021-11-27T09:40:01.173831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    590\n",
       " 0     56\n",
       " 1     44\n",
       "Name: New Label, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"New Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi Supervised Learning\n",
    "Semi-supervised learning is the branch of machine learning concerned with using labelled\n",
    "as well as unlabelled data to perform certain learning tasks. Generally, the main intrest of research on semi-supervised learning is focused on classification. Semi-supervised classification methods are\n",
    "particularly relevant to scenarios where labelled data is scarce. In those cases, it may be\n",
    "difficult to construct a reliable supervised classifier. This situation occurs in application\n",
    "domains where labelled data is expensive or difficult obtain, like computer-aided diagnosis,\n",
    "drug discovery and part-of-speech tagging. If sufficient unlabelled data is available and under\n",
    "certain assumptions about the distribution of the data, the unlabelled data can help in the\n",
    "construction of a better classifier.\n",
    "\n",
    "## Inductive\n",
    "**Definition:** Induction is reasoning from observed training cases to general rules, which are then applied to the test cases.\n",
    "\n",
    "Inductive learning is the same as what we commonly know as traditional supervised learning. We build and train a machine learning model based on a labelled training dataset we already have. Then we use this trained model to predict the labels of a testing dataset which we have never encountered before.\n",
    "\n",
    "### Wrapper Methods\n",
    "A simple approach to extending existing, supervised algorithms to the semi-supervised setting\n",
    "is to first train classifiers on labelled data, and to then use the predictions of the resulting\n",
    "classifiers to generate additional labelled data. The classifiers can then be re-trained on this\n",
    "pseudo-labelled data in addition to the existing labelled data. Such methods are known as\n",
    "wrapper methods: the unlabelled data is pseudo-labelled by a wrapper procedure, and a\n",
    "purely supervised learning algorithm, unaware of the distinction between originally labelled\n",
    "and pseudo-labelled data, constructs the final inductive classifier.\n",
    "\n",
    "#### Self Training\n",
    "Self-training methods consist of a single supervised\n",
    "classifier that is iteratively trained on both labelled data and data that has been pseudo-labelled\n",
    "in previous iterations of the algorithm. At the beginning of the self-training procedure, a supervised classifier is trained on only the labelled data. The resulting classifier is used to obtain predictions for the unlabelled data points. Then, the most confident of these predictions are added to the labelled data set, and the supervised classifier is re-trained on both the original labelled data and the newly obtained pseudo-labelled data. This procedure is typically iterated until no more unlabelled data remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T09:40:05.917298Z",
     "start_time": "2021-11-27T09:40:05.910317Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T09:40:09.040123Z",
     "start_time": "2021-11-27T09:40:09.028166Z"
    }
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "self_training_model = SelfTrainingClassifier(gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T11:57:37.791315Z",
     "start_time": "2021-11-27T11:57:37.771368Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true = X_test[:, -1] ## target column\n",
    "X_test = X_test[:,:-1] ## drop target column\n",
    "X_train = X_train[:,:-1] ## drop target column\n",
    "\n",
    "#Before we fit any models, we need to scale our features: this ensures all features \n",
    "#are on the same numerical scale\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T09:40:24.300402Z",
     "start_time": "2021-11-27T09:40:24.279461Z"
    }
   },
   "outputs": [],
   "source": [
    "self_training_model.fit(X_train, y_train)\n",
    "y_pred=self_training_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T09:40:26.851467Z",
     "start_time": "2021-11-27T09:40:26.832817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.89      0.82       115\n",
      "         1.0       0.82      0.64      0.72        92\n",
      "\n",
      "    accuracy                           0.78       207\n",
      "   macro avg       0.79      0.76      0.77       207\n",
      "weighted avg       0.78      0.78      0.77       207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Preprocessing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised preprocessing use the\n",
    "unlabelled data and labelled data in two separate stages. Typically, the unsupervised stage comprises either the automated extraction or transformation of sample features from the unlabelled data (feature extraction), the unsupervised clustering of the data (cluster-then-label), or the initialization of the parameters of the learning procedure (pre-training)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster then Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many semi-supervised learning algorithms use principles from clustering to\n",
    "guide the classification process. Cluster-then-label approaches usually apply an unsupervised or\n",
    "semi-supervised clustering algorithm to all available data, and use the resulting clusters to\n",
    "guide the classification process. In our case, we cluster both labelled and unlabelled coming from train dataset and then we use the mojority of labelled instances in each cluster to assign a label in the whole cluster. That way, training dataset which previously contained both labelled and unlabelled data, now contains only labelled data. In this dataset we apply a supervised learning method (Logistic Regression) and then based on that learner we predict our test data originating from the initial splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T09:41:43.866114Z",
     "start_time": "2021-11-27T09:41:43.849647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(483, 14)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "y_true = X_test[:, -1] ## target column\n",
    "X_test = X_test[:,:-1] ## drop target column\n",
    "X_train = X_train[:,:-1] ## drop target column\n",
    "\n",
    "#Before we fit any models, we need to scale our features: this ensures all features \n",
    "#are on the same numerical scale\n",
    "train_scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = train_scaler.transform(X_train)\n",
    "X_test = train_scaler.transform(X_test)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T09:42:04.993682Z",
     "start_time": "2021-11-27T09:42:04.871011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>C4_enc</th>\n",
       "      <th>C5_enc</th>\n",
       "      <th>C6_enc</th>\n",
       "      <th>N7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>N10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12_enc</th>\n",
       "      <th>N13</th>\n",
       "      <th>N14</th>\n",
       "      <th>clusters</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.394676</td>\n",
       "      <td>1.160665</td>\n",
       "      <td>-0.736898</td>\n",
       "      <td>0.594187</td>\n",
       "      <td>0.991905</td>\n",
       "      <td>-0.343704</td>\n",
       "      <td>-0.669543</td>\n",
       "      <td>-1.053172</td>\n",
       "      <td>-0.844255</td>\n",
       "      <td>-0.477545</td>\n",
       "      <td>1.093368</td>\n",
       "      <td>0.253330</td>\n",
       "      <td>0.473758</td>\n",
       "      <td>-0.239587</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.394676</td>\n",
       "      <td>2.042573</td>\n",
       "      <td>0.497563</td>\n",
       "      <td>0.594187</td>\n",
       "      <td>-0.932152</td>\n",
       "      <td>1.656403</td>\n",
       "      <td>1.532486</td>\n",
       "      <td>0.949513</td>\n",
       "      <td>1.184477</td>\n",
       "      <td>0.123117</td>\n",
       "      <td>1.093368</td>\n",
       "      <td>0.253330</td>\n",
       "      <td>-0.450387</td>\n",
       "      <td>-0.227492</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.394676</td>\n",
       "      <td>-0.637853</td>\n",
       "      <td>-0.838416</td>\n",
       "      <td>0.594187</td>\n",
       "      <td>0.991905</td>\n",
       "      <td>1.656403</td>\n",
       "      <td>-0.295613</td>\n",
       "      <td>0.949513</td>\n",
       "      <td>1.184477</td>\n",
       "      <td>-0.277325</td>\n",
       "      <td>-0.914605</td>\n",
       "      <td>0.253330</td>\n",
       "      <td>-1.017347</td>\n",
       "      <td>-0.075573</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.717012</td>\n",
       "      <td>-0.729260</td>\n",
       "      <td>-0.787657</td>\n",
       "      <td>0.594187</td>\n",
       "      <td>-0.107556</td>\n",
       "      <td>-0.343704</td>\n",
       "      <td>-0.544900</td>\n",
       "      <td>0.949513</td>\n",
       "      <td>-0.844255</td>\n",
       "      <td>-0.477545</td>\n",
       "      <td>1.093368</td>\n",
       "      <td>-3.053649</td>\n",
       "      <td>0.796925</td>\n",
       "      <td>-0.239587</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.394676</td>\n",
       "      <td>-1.342872</td>\n",
       "      <td>-0.863796</td>\n",
       "      <td>0.594187</td>\n",
       "      <td>0.167309</td>\n",
       "      <td>-0.343704</td>\n",
       "      <td>-0.378709</td>\n",
       "      <td>-1.053172</td>\n",
       "      <td>-0.844255</td>\n",
       "      <td>-0.477545</td>\n",
       "      <td>-0.914605</td>\n",
       "      <td>0.253330</td>\n",
       "      <td>-0.336995</td>\n",
       "      <td>-0.235233</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C1        N2        N3    C4_enc    C5_enc    C6_enc        N7  \\\n",
       "0 -1.394676  1.160665 -0.736898  0.594187  0.991905 -0.343704 -0.669543   \n",
       "1 -1.394676  2.042573  0.497563  0.594187 -0.932152  1.656403  1.532486   \n",
       "2 -1.394676 -0.637853 -0.838416  0.594187  0.991905  1.656403 -0.295613   \n",
       "3  0.717012 -0.729260 -0.787657  0.594187 -0.107556 -0.343704 -0.544900   \n",
       "4 -1.394676 -1.342872 -0.863796  0.594187  0.167309 -0.343704 -0.378709   \n",
       "\n",
       "         C8        C9       N10       C11   C12_enc       N13       N14  \\\n",
       "0 -1.053172 -0.844255 -0.477545  1.093368  0.253330  0.473758 -0.239587   \n",
       "1  0.949513  1.184477  0.123117  1.093368  0.253330 -0.450387 -0.227492   \n",
       "2  0.949513  1.184477 -0.277325 -0.914605  0.253330 -1.017347 -0.075573   \n",
       "3  0.949513 -0.844255 -0.477545  1.093368 -3.053649  0.796925 -0.239587   \n",
       "4 -1.053172 -0.844255 -0.477545 -0.914605  0.253330 -0.336995 -0.235233   \n",
       "\n",
       "   clusters  true  \n",
       "0         1    -1  \n",
       "1         0     0  \n",
       "2         0    -1  \n",
       "3         1    -1  \n",
       "4         1    -1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#UNSUPERVISED PREPROCESSING \n",
    "clustering = KMeans(n_clusters=2, random_state=42,n_jobs=-1)\n",
    "clustering.fit(X_train)\n",
    "\n",
    "# apply the labels\n",
    "train_labels = clustering.labels_\n",
    "\n",
    "df = X_train.copy()\n",
    "column_names = list(dataset.columns)\n",
    "column_names.pop(-1) #remove New Label column name\n",
    "column_names.pop(-1) #remove Target column name\n",
    "\n",
    "df = pd.DataFrame(X_train , columns = column_names)\n",
    "\n",
    "df['clusters'] = train_labels\n",
    "\n",
    "df[\"true\"] = y_train\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T09:42:10.182081Z",
     "start_time": "2021-11-27T09:42:10.171111Z"
    }
   },
   "outputs": [],
   "source": [
    "df0=df[df.clusters==0] #cluster 0\n",
    "df1=df[df.clusters==1] #cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T09:42:12.711333Z",
     "start_time": "2021-11-27T09:42:12.702357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    158\n",
       " 1     19\n",
       " 0      6\n",
       "Name: true, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0[\"true\"].value_counts()  #most appearances from class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T09:42:16.666299Z",
     "start_time": "2021-11-27T09:42:16.646353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    263\n",
       " 0     32\n",
       " 1      5\n",
       "Name: true, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"true\"].value_counts() #most appearances from class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T09:42:22.560177Z",
     "start_time": "2021-11-27T09:42:22.543225Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df['clusters'] == 0, 'predicted'] = 1\n",
    "df.loc[df['clusters'] == 1, 'predicted'] = 0\n",
    "df = df.drop('clusters',axis=1)\n",
    "df = df.drop('true',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T10:03:00.722162Z",
     "start_time": "2021-11-27T10:03:00.683269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>C4_enc</th>\n",
       "      <th>C5_enc</th>\n",
       "      <th>C6_enc</th>\n",
       "      <th>N7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>N10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12_enc</th>\n",
       "      <th>N13</th>\n",
       "      <th>N14</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.394676</td>\n",
       "      <td>1.160665</td>\n",
       "      <td>-0.736898</td>\n",
       "      <td>0.594187</td>\n",
       "      <td>0.991905</td>\n",
       "      <td>-0.343704</td>\n",
       "      <td>-0.669543</td>\n",
       "      <td>-1.053172</td>\n",
       "      <td>-0.844255</td>\n",
       "      <td>-0.477545</td>\n",
       "      <td>1.093368</td>\n",
       "      <td>0.253330</td>\n",
       "      <td>0.473758</td>\n",
       "      <td>-0.239587</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.394676</td>\n",
       "      <td>2.042573</td>\n",
       "      <td>0.497563</td>\n",
       "      <td>0.594187</td>\n",
       "      <td>-0.932152</td>\n",
       "      <td>1.656403</td>\n",
       "      <td>1.532486</td>\n",
       "      <td>0.949513</td>\n",
       "      <td>1.184477</td>\n",
       "      <td>0.123117</td>\n",
       "      <td>1.093368</td>\n",
       "      <td>0.253330</td>\n",
       "      <td>-0.450387</td>\n",
       "      <td>-0.227492</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.394676</td>\n",
       "      <td>-0.637853</td>\n",
       "      <td>-0.838416</td>\n",
       "      <td>0.594187</td>\n",
       "      <td>0.991905</td>\n",
       "      <td>1.656403</td>\n",
       "      <td>-0.295613</td>\n",
       "      <td>0.949513</td>\n",
       "      <td>1.184477</td>\n",
       "      <td>-0.277325</td>\n",
       "      <td>-0.914605</td>\n",
       "      <td>0.253330</td>\n",
       "      <td>-1.017347</td>\n",
       "      <td>-0.075573</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.717012</td>\n",
       "      <td>-0.729260</td>\n",
       "      <td>-0.787657</td>\n",
       "      <td>0.594187</td>\n",
       "      <td>-0.107556</td>\n",
       "      <td>-0.343704</td>\n",
       "      <td>-0.544900</td>\n",
       "      <td>0.949513</td>\n",
       "      <td>-0.844255</td>\n",
       "      <td>-0.477545</td>\n",
       "      <td>1.093368</td>\n",
       "      <td>-3.053649</td>\n",
       "      <td>0.796925</td>\n",
       "      <td>-0.239587</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.394676</td>\n",
       "      <td>-1.342872</td>\n",
       "      <td>-0.863796</td>\n",
       "      <td>0.594187</td>\n",
       "      <td>0.167309</td>\n",
       "      <td>-0.343704</td>\n",
       "      <td>-0.378709</td>\n",
       "      <td>-1.053172</td>\n",
       "      <td>-0.844255</td>\n",
       "      <td>-0.477545</td>\n",
       "      <td>-0.914605</td>\n",
       "      <td>0.253330</td>\n",
       "      <td>-0.336995</td>\n",
       "      <td>-0.235233</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C1        N2        N3    C4_enc    C5_enc    C6_enc        N7  \\\n",
       "0 -1.394676  1.160665 -0.736898  0.594187  0.991905 -0.343704 -0.669543   \n",
       "1 -1.394676  2.042573  0.497563  0.594187 -0.932152  1.656403  1.532486   \n",
       "2 -1.394676 -0.637853 -0.838416  0.594187  0.991905  1.656403 -0.295613   \n",
       "3  0.717012 -0.729260 -0.787657  0.594187 -0.107556 -0.343704 -0.544900   \n",
       "4 -1.394676 -1.342872 -0.863796  0.594187  0.167309 -0.343704 -0.378709   \n",
       "\n",
       "         C8        C9       N10       C11   C12_enc       N13       N14  \\\n",
       "0 -1.053172 -0.844255 -0.477545  1.093368  0.253330  0.473758 -0.239587   \n",
       "1  0.949513  1.184477  0.123117  1.093368  0.253330 -0.450387 -0.227492   \n",
       "2  0.949513  1.184477 -0.277325 -0.914605  0.253330 -1.017347 -0.075573   \n",
       "3  0.949513 -0.844255 -0.477545  1.093368 -3.053649  0.796925 -0.239587   \n",
       "4 -1.053172 -0.844255 -0.477545 -0.914605  0.253330 -0.336995 -0.235233   \n",
       "\n",
       "   predicted  \n",
       "0        0.0  \n",
       "1        1.0  \n",
       "2        1.0  \n",
       "3        0.0  \n",
       "4        0.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T09:42:31.542238Z",
     "start_time": "2021-11-27T09:42:31.492375Z"
    }
   },
   "outputs": [],
   "source": [
    "# use supervised techniques to train the data derived fron unsupervised prepocessing\n",
    "y_train = df['predicted'] ## target column\n",
    "x_train = df.drop('predicted',axis=1)\n",
    "# all parameters not specified are set to their defaults\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "y_pred = logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T09:42:34.930275Z",
     "start_time": "2021-11-27T09:42:34.915315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.91      0.85       115\n",
      "         1.0       0.87      0.72      0.79        92\n",
      "\n",
      "    accuracy                           0.83       207\n",
      "   macro avg       0.83      0.82      0.82       207\n",
      "weighted avg       0.83      0.83      0.82       207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intrinsically semi-supervised method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines\n",
    "\n",
    "The objective of an SVM is to find a decision boundary that maximizes the margin, which\n",
    "is defined as the distance between the decision boundary and the data points closest to it.\n",
    "\n",
    "The concept of semi-supervised SVMs, or S3VMs, is similar: we want to maximize the\n",
    "margin, and we want to correctly classify the labelled data. However, in the semi-supervised\n",
    "setting, an additional objective becomes relevant: we also want to minimize the number of\n",
    "unlabelled data points that violate the margin. Since the labels of the unlabelled data points are\n",
    "unknown, those that violate (i.e. lie within) the margin are penalized based on their distance\n",
    "to the closest margin boundary. \n",
    "\n",
    "S3VMs were proposed by Vapnik (1998), who motivated the problem from a more transductive viewpoint: instead of optimizing only over the weight vector, bias and slack variables, he proposed to also optimize over the label predictions $y^{U}$ . This formulation is equivalent to optimization problem,\n",
    "since any labelling $yˆ{U}$ can only be optimal if, for each $y^{i}$ ∈ $y^{U}$ , $x_{i}$ is on the correct side of the decision boundary. Otherwise, a better solution could be obtained by simply inverting the labelling of $x_{i}$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T10:10:25.505493Z",
     "start_time": "2021-11-27T10:10:25.478557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 14)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled = dataset.loc[dataset['New Label'] != -1]\n",
    "unlabeled = dataset.loc[dataset['New Label'] == -1]\n",
    "\n",
    "X_labeled = labeled.iloc[:, :-1].values\n",
    "y_labeled = labeled.iloc[:, -1].values\n",
    "\n",
    "X_unlabeled = unlabeled.iloc[:, :-2].values\n",
    "y_unlabeled = unlabeled.iloc[:, -1].values\n",
    "\n",
    "label_X_train, label_X_test, label_y_train, label_y_test = train_test_split(X_labeled, y_labeled, test_size=0.3, random_state=1)\n",
    "label_X_test = label_X_test[:,:-1] ## drop target column\n",
    "label_X_train = label_X_train[:,:-1] ## drop target column\n",
    "\n",
    "#Before we fit any models, we need to scale our features: this ensures all features \n",
    "#are on the same numerical scale\n",
    "train = np.append(label_X_train, X_unlabeled, axis = 0)\n",
    "train_scaler = preprocessing.StandardScaler().fit(train)\n",
    "label_X_train = train_scaler.transform(label_X_train)\n",
    "X_unlabeled = train_scaler.transform(X_unlabeled)\n",
    "label_X_test = train_scaler.transform(label_X_test)\n",
    "label_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T10:10:36.759330Z",
     "start_time": "2021-11-27T10:10:35.731522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70        15\n",
      "           1       1.00      0.13      0.24        15\n",
      "\n",
      "    accuracy                           0.57        30\n",
      "   macro avg       0.77      0.57      0.47        30\n",
      "weighted avg       0.77      0.57      0.47        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = S3VM()\n",
    "\n",
    "model.fit(np.concatenate((label_X_train, X_unlabeled)), np.append(label_y_train, y_unlabeled))\n",
    "# predict\n",
    "predict = model.predict(label_X_test)\n",
    "\n",
    "print (classification_report(label_y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transductive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T11:54:22.051005Z",
     "start_time": "2021-11-27T11:54:22.030086Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_mixed, X_test_mixed, y_train_mixed, y_test_mixed = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "y_true = X_test_mixed[:,-1]\n",
    "X_train_mixed = X_train_mixed[:,:-1] ## drop target column\n",
    "X_test_mixed = X_test_mixed[:,:-1] ## drop target column\n",
    "\n",
    "#Before we fit any models, we need to scale our features: this ensures all features \n",
    "#are on the same numerical scale\n",
    "train_scaler = preprocessing.StandardScaler().fit(X_train_mixed)\n",
    "X_train_mixed = train_scaler.transform(X_train_mixed)\n",
    "X_test_mixed = train_scaler.transform(X_test_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T11:52:57.223297Z",
     "start_time": "2021-11-27T11:52:57.080712Z"
    }
   },
   "outputs": [],
   "source": [
    "lp = LabelPropagation(gamma=.25)\n",
    "lp.fit(X_train_mixed, y_train_mixed)\n",
    "# get labels for entire training dataset data\n",
    "tran_labels = lp.transduction_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T11:50:26.389534Z",
     "start_time": "2021-11-27T11:50:26.377565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(483,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T11:54:40.138430Z",
     "start_time": "2021-11-27T11:54:40.101531Z"
    }
   },
   "outputs": [],
   "source": [
    "# all parameters not specified are set to their defaults\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(X_train_mixed, tran_labels)\n",
    "y_pred = logisticRegr.predict(X_test_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T11:55:07.265559Z",
     "start_time": "2021-11-27T11:55:07.241589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.98      0.77       115\n",
      "         1.0       0.93      0.30      0.46        92\n",
      "\n",
      "    accuracy                           0.68       207\n",
      "   macro avg       0.79      0.64      0.62       207\n",
      "weighted avg       0.77      0.68      0.63       207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
