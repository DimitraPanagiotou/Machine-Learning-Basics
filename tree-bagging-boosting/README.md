# Tree Bagging and Boosting

Gradient boosting algorithms are broadly used as alternatives to neural nets so as to solve classification and regression problems.
In this project, a complete introduction to gradient based algorithms for regression problems has been presented. This implementation uses python supported libraries such as sklearn, numpy, pandas and matplotlib. Furthermore, a classification problem analysis for the pima-indian-diabetes dataset utilizing the `diabetes.csv` dataset is presented.

Project milestones:
- Gradient boosting with default loss function(deviance)
- Gradient boosting with exponential loss function
- Observe data behavior in different learning rates and estimators
- Compare RandomForestClassifier with GradientBoostingClassifier concerning learning rate and overfitting
- Presentation of Xgboost 
- Presentation of LGBMClassifier
- Presentation of Catboost

